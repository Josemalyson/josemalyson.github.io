"use strict";(self.webpackChunkjosemalyson_github_io=self.webpackChunkjosemalyson_github_io||[]).push([[7206],{70:(e,a,o)=>{o.r(a),o.d(a,{assets:()=>d,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>t,toc:()=>l});var s=o(4848),n=o(8453);const i={sidebar_position:1},r="Amazon Bedrock",t={id:"aws/bedrock",title:"Amazon Bedrock",description:"O amazon Bedrorck \xe9 um servi\xe7o da AWS para construir e escalar de maneira f\xe1cil aplica\xe7\xf5es de IA Generativa (Generative AI) com modelos fundacionais. Disponibilizando os modelos atrav\xe9s de uma simples chamada via API, gerando aplica\xe7\xe3oes de generative AI com seguran\xe7a, privacidade e responsabilidade AI.",source:"@site/docs/aws/bedrock.md",sourceDirName:"aws",slug:"/aws/bedrock",permalink:"/docs/aws/bedrock",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/aws/bedrock.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"AWS",permalink:"/docs/category/aws"}},d={},l=[{value:"Modelos suportados",id:"modelos-suportados",level:2},{value:"Explorando o poder da generative AI",id:"explorando-o-poder-da-generative-ai",level:2},{value:"Text summarization",id:"text-summarization",level:3},{value:"Text generation",id:"text-generation",level:3},{value:"Question answering systems",id:"question-answering-systems",level:3},{value:"Agents",id:"agents",level:3},{value:"Componentes tipicos de uma aplica\xe7\xe3o com generative AI (Application Components)",id:"componentes-tipicos-de-uma-aplica\xe7\xe3o-com-generative-ai-application-components",level:2},{value:"Foundation Models (Modelos Fundacionais ) e FM Interface",id:"foundation-models-modelos-fundacionais--e-fm-interface",level:2},{value:"Foundation model interface",id:"foundation-model-interface",level:3},{value:"Interface and prompts",id:"interface-and-prompts",level:3},{value:"Inference parameters",id:"inference-parameters",level:3},{value:"Top P or nucleus sampling",id:"top-p-or-nucleus-sampling",level:4},{value:"Top K",id:"top-k",level:4},{value:"Temperature",id:"temperature",level:4},{value:"Enterprise Datasets",id:"enterprise-datasets",level:2},{value:"Embeddings",id:"embeddings",level:3},{value:"Vector databases",id:"vector-databases",level:3},{value:"Vectorized enterprise data",id:"vectorized-enterprise-data",level:3},{value:"Additional Application Components",id:"additional-application-components",level:2},{value:"Prompt history store",id:"prompt-history-store",level:3},{value:"RAG",id:"rag",level:2},{value:"RAG visualmente",id:"rag-visualmente",level:3},{value:"Model Fine-Tuning",id:"model-fine-tuning",level:3},{value:"Prompt-based learning",id:"prompt-based-learning",level:4},{value:"Domain adaptation",id:"domain-adaptation",level:4}];function c(e){const a={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",ul:"ul",...(0,n.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(a.h1,{id:"amazon-bedrock",children:"Amazon Bedrock"}),"\n",(0,s.jsx)(a.p,{children:"O amazon Bedrorck \xe9 um servi\xe7o da AWS para construir e escalar de maneira f\xe1cil aplica\xe7\xf5es de IA Generativa (Generative AI) com modelos fundacionais. Disponibilizando os modelos atrav\xe9s de uma simples chamada via API, gerando aplica\xe7\xe3oes de generative AI com seguran\xe7a, privacidade e responsabilidade AI."}),"\n",(0,s.jsx)(a.p,{children:"Utilizando o conceito de t\xe9cnicas de customiza\xe7\xe3o de uso dos modelos como fine-tuning e Retrieval Augmented Generation (RAG)."}),"\n",(0,s.jsx)(a.p,{children:"O Amazon Bedrock \xe9 um servi\xe7o serveless onde voc\xea n\xe3o precisa gerenciar sua infra-estrutura."}),"\n",(0,s.jsx)(a.h2,{id:"modelos-suportados",children:"Modelos suportados"}),"\n",(0,s.jsx)(a.p,{children:"Abaixo temos alguns dos modelos suportados, para uso, sendo eles:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:"AI21 Labs"}),"\n",(0,s.jsx)(a.li,{children:"Anthropic"}),"\n",(0,s.jsx)(a.li,{children:"Cohere"}),"\n",(0,s.jsx)(a.li,{children:"Meta"}),"\n",(0,s.jsx)(a.li,{children:"Mistral AI"}),"\n",(0,s.jsx)(a.li,{children:"Stability AI"}),"\n"]}),"\n",(0,s.jsx)(a.h2,{id:"explorando-o-poder-da-generative-ai",children:"Explorando o poder da generative AI"}),"\n",(0,s.jsx)(a.p,{children:"Com o uso do NLP (Natural Language Processing) podemos ter algumas a\xe7\xf5es que podem ser realiadas sendo elas: Text summarization, Text generation, Question answering systems, Agents."}),"\n",(0,s.jsx)(a.h3,{id:"text-summarization",children:"Text summarization"}),"\n",(0,s.jsx)(a.p,{children:"Como o propr\xedo nome nos tr\xe1s refer\xeancia, podemos resumir ou filtrar grandes quantidades de informa\xe7\xf5es utilizando o modelo de LLM ou os FMs (Modelos fundacionais), nos ajudando\nh\xe1 entender informa\xe7\xf5es chaves sobre um determinado assunto de forma limpa e objetiva."}),"\n",(0,s.jsx)(a.h3,{id:"text-generation",children:"Text generation"}),"\n",(0,s.jsx)(a.p,{children:"Nesse cen\xe1rio temos a op\xe7\xe3o de contextualizar os modelos com o objetivo de gerar novos argumentos como resposta, trazendo uma gera\xe7\xe3o mais realista\nda linguagem humana e melhorando a compreens\xe3o de dados, utilizamos as tecnicas que inclue o uso do LangChain e do  Retrieval Augmented Generation (RAG) com a persistecia de embeddings\npara contextualizar nosso modelo."}),"\n",(0,s.jsx)(a.h3,{id:"question-answering-systems",children:"Question answering systems"}),"\n",(0,s.jsx)(a.p,{children:"Basicamente essa op\xe7\xe3o \xe9 a sa\xeddas das informa\xe7\xf5es montadas pelo Text generation dando a possibilidade do usu\xe1rio interagir via modelo de implementa\xe7\xe3o como um chatbot, para entender e buscar informa\xe7\xf5es\ndadas ao seu contexto."}),"\n",(0,s.jsx)(a.h3,{id:"agents",children:"Agents"}),"\n",(0,s.jsx)(a.p,{children:"S\xe3o capazes de entender a linguagem natural requistitadas pelo usu\xe1rio para disponibilizar chamadas via API facilitando a complexidade de tarefas de acesso direto ao modelo. O servi\xe7o de prompt engineering especifico\nde uma company-specific ou domain-specific. No Amazon Bedrock os agentes podem gerenciar infraestrutura, monitoramento, criptografia, permiss\xf5es e invoca\xe7\xf5es senm customiza\xe7\xe3o de c\xf3digo."}),"\n",(0,s.jsx)(a.h2,{id:"componentes-tipicos-de-uma-aplica\xe7\xe3o-com-generative-ai-application-components",children:"Componentes tipicos de uma aplica\xe7\xe3o com generative AI (Application Components)"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"alt text",src:o(1594).A+"",width:"865",height:"819"})}),"\n",(0,s.jsx)(a.admonition,{title:"Fonte",type:"tip",children:(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components",children:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components"})})}),"\n",(0,s.jsx)(a.h2,{id:"foundation-models-modelos-fundacionais--e-fm-interface",children:"Foundation Models (Modelos Fundacionais ) e FM Interface"}),"\n",(0,s.jsx)(a.h3,{id:"foundation-model-interface",children:"Foundation model interface"}),"\n",(0,s.jsx)(a.p,{children:"As interfaces funcionais de modelo s\xe3o o cora\xe7\xe3o da generative AI, ou seja os pr\xf3prios modelos treinanos com uma enorme escala de dados, s\xe3o disponibilizados para atender a um determinado requisito do usu\xe1rio."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"alt text",src:o(7688).A+"",width:"1015",height:"426"})}),"\n",(0,s.jsx)(a.admonition,{title:"Fonte",type:"tip",children:(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components",children:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components"})})}),"\n",(0,s.jsx)(a.h3,{id:"interface-and-prompts",children:"Interface and prompts"}),"\n",(0,s.jsx)(a.p,{children:"Para que seja poss\xedvel acessar o modelo \xe9 necess\xe1rio que seja fornecido uma interface de (entrada) dados, geralmente temos a disponibiliza\xe7\xe3o de APIs, onde a mesma atrav\xe9s de uma requisi\xe7\xe3o \xe9 capaz de trazer as respostas enviadas via prompt."}),"\n",(0,s.jsx)(a.h3,{id:"inference-parameters",children:"Inference parameters"}),"\n",(0,s.jsx)(a.p,{children:"Durante o uso de prompts, efetivamente os Inference parameters causam uma forte influ\xeancia no output dos Foundation model. As LLMs operam com o uso de token, que podem ser palavaras, letras ou apenas uma parte de uma frase."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.code,{children:"Mil tokens s\xe3o aproximadamente 750 palavras."})}),"\n",(0,s.jsx)(a.h4,{id:"top-p-or-nucleus-sampling",children:"Top P or nucleus sampling"}),"\n",(0,s.jsx)(a.p,{children:"Neste controle de tecnica \xe9 respos\xe1vel por escolher a menor probabilidade de combina\xe7\xe3o de acertividade para o pr\xf3ximo token. Uma alto valor par o Top P como 0.9 pode tornar o resultado o mais deterministico e previsiv\xe9l. Com valores menores pode trazer tokens incoerentes ent\xe3o \xe9 essencial balancear o seu valor."}),"\n",(0,s.jsx)(a.h4,{id:"top-k",children:"Top K"}),"\n",(0,s.jsx)(a.p,{children:"Top K, reduz o tamanho do pr\xf3ximo tokens. Tipicamente os valores 10 para 100, o valor de 1 \xe9 chamado de greedy strategy, porque provavelmente o token mais provav\xe9l \xe9 sempre escolhido."}),"\n",(0,s.jsx)(a.h4,{id:"temperature",children:"Temperature"}),"\n",(0,s.jsx)(a.p,{children:"Enquanto o Top P and Top K controlam o qual tokens s\xe3o escolhidos baseados no output dos modelos, o parametro de temperature afeta a sa\xedda do modelo diretamente."}),"\n",(0,s.jsx)(a.p,{children:"Quando o valor dessa temperatura \xe9 alto, a distribui\xe7\xe3o da probabilidade de conhecimento dos tokens deveria ser uniforme, tornando a resposta dos tokens gerados, mais criativos e uniformes."}),"\n",(0,s.jsx)(a.p,{children:"Quando o valor dessa temperatura \xe9 baixo, com uma distribui\xe7\xe3o polarizada, se tem sa\xeddas poss\xedveis mais deterministicas."}),"\n",(0,s.jsx)(a.h2,{id:"enterprise-datasets",children:"Enterprise Datasets"}),"\n",(0,s.jsx)(a.p,{children:"Apesar dos Foundation Models poderem gerar textos humanos, imagens, audios dos prompts escritos, isso n\xe3o \xe9 o suficiente para gerar os casos de usos de neg\xf3cio.\nPois para se gerar algo relevante ao neg\xf3cio da empresa, \xe9 necess\xe1rio que se conhe\xe7a os dados internos acumulados, exemplos disso seria: documentos, aparesenta\xe7\xf5es, manuais de usu\xe1ios, relat\xf3rios, textos sumarizados, \xe1udios transcritos e etc."}),"\n",(0,s.jsx)(a.p,{children:"Para a ingest\xe3o e utiliza\xe7\xe3o desses recursos fornecidos para o Foundation Models, s\xe3o conhecidos como domain-specific, ou seja, outputs altamente relevantes para a neg\xf3cio."}),"\n",(0,s.jsx)(a.h3,{id:"embeddings",children:"Embeddings"}),"\n",(0,s.jsx)(a.p,{children:"Embeddings \xe9 um processo no quais os texos, imagens e audios s\xe3o num\xe9ricamente representados em um espa\xe7o de vetor. Embeddings geralmente s\xe3o utilizados em t\xe9cnicas de modelo de machine learning."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"alt text",src:o(2963).A+"",width:"893",height:"584"})}),"\n",(0,s.jsx)(a.admonition,{title:"Fonte",type:"tip",children:(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components",children:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components"})})}),"\n",(0,s.jsx)(a.p,{children:"Para os Enterprise Datasets, como os documentoss, imagens e audios, s\xe3o passadas para o ML models com tokens e s\xe3o vetorizados. Estes vetores est\xe3o s\xe3o os n-dimensional space, ou seja alocados em um determinado espa\xe7o onde estes dados., s\xe3o armazenados em vector databases para que seja poss\xedvel obter uma resposta r\xe1pida."}),"\n",(0,s.jsx)(a.p,{children:"Basicamente a busca semantica de um token \xe9 feita atrav\xe9s de textos similares em um espa\xe7o do vetor muilti-dimensioal."}),"\n",(0,s.jsxs)(a.p,{children:["Um exemplo de provide \xe9 o ",(0,s.jsx)(a.a,{href:"https://aws.amazon.com/bedrock/titan/?gclid=Cj0KCQjw2PSvBhDjARIsAKc2cgMvAC0PxitQA_c83GjxoGRwriiiD1c-vv9NE33C4S5QXVaBTgCZ67saAnz2EALw_wcB&trk=82b1c10f-8aa4-4e6c-ab52-c75550a4a31e&sc_channel=ps&ef_id=Cj0KCQjw2PSvBhDjARIsAKc2cgMvAC0PxitQA_c83GjxoGRwriiiD1c-vv9NE33C4S5QXVaBTgCZ67saAnz2EALw_wcB:G:s&s_kwcid=AL!4422!3!692006001535!p!!g!!amazon%20titan!21054971723!164977098451",children:"Amazon Titan Embeddings G1"}),"."]}),"\n",(0,s.jsx)(a.h3,{id:"vector-databases",children:"Vector databases"}),"\n",(0,s.jsx)(a.p,{children:"O core funcional dos vector databases \xe9 o compactamento do armazenamento de bilh\xf5es de vetores high-dimensional representados por palavras ou entidades. Esses databases fornecem uma ultra velocidade na busca similar de dados. Pecorrendo bilh\xf5es de vetores em tempo real."}),"\n",(0,s.jsxs)(a.p,{children:["Os algoritmos mais comuns utilizados s\xe3o o ",(0,s.jsx)(a.a,{href:"https://www.ibm.com/topics/knn#:~:text=The%20k%2Dnearest%20neighbors%20(KNN)%20algorithm%20is%20a%20non,of%20an%20individual%20data%20point.",children:"k-nearest neighbors (k-NN)"})," or ",(0,s.jsx)(a.a,{href:"https://www.learndatasci.com/glossary/cosine-similarity/",children:"cosine similatrity"}),"."]}),"\n",(0,s.jsx)(a.p,{children:"A AWS oferece os seguintes op\xe7\xf5es de vectors databases:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://docs.aws.amazon.com/opensearch-service/latest/developerguide/knn.html",children:"Amazon OpenSearch Service (provisioned)"})}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://aws.amazon.com/opensearch-service/serverless-vector-engine/",children:"Amazon OpenSearch Serverless"})}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Appendix.PostgreSQL.CommonDBATasks.Extensions.html",children:"pgvector extension in Amazon Relational Database Service (Amazon RDS) for PostgreSQL"})}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://aws.amazon.com/about-aws/whats-new/2023/07/amazon-aurora-postgresql-pgvector-vector-storage-similarity-search/",children:"pgvector extension in Amazon Aurora PostgreSQL - Compatible Edition"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"A AWS tamb\xe9m oferece solu\xe7\xf5es open source como:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://aws.amazon.com/marketplace/pp/prodview-xhgyscinlz4jk",children:"Pinecone"})}),"\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://github.com/facebookresearch/faiss",children:"FAISS"})}),"\n",(0,s.jsx)(a.li,{children:(0,s.jsx)(a.a,{href:"https://www.trychroma.com/",children:"Chroma"})}),"\n"]}),"\n",(0,s.jsx)(a.h3,{id:"vectorized-enterprise-data",children:"Vectorized enterprise data"}),"\n",(0,s.jsxs)(a.p,{children:["Depois que os dados de neg\xf3cios est\xe3o vetorizados, voc\xea pode procurar via prompt os dados armazendados. Com os famosos chunks de informa\xe7\xf5es como um contexto fornecido para o seu modelo de AI generativo, evitando assim as alucina\xe7\xf5es. Vector Databases e context s\xe3o usados em ",(0,s.jsx)(a.a,{href:"https://python.langchain.com/docs/use_cases/question_answering/",children:"Retrieval Augmented Generation"})," (RAG)."]}),"\n",(0,s.jsx)(a.h2,{id:"additional-application-components",children:"Additional Application Components"}),"\n",(0,s.jsx)(a.h3,{id:"prompt-history-store",children:"Prompt history store"}),"\n",(0,s.jsx)(a.p,{children:"O armazenamento dos hist\xf3ricos de prompts, s\xe3o um componente essencial para as aplica\xe7\xf5es de generative AI, particulamente usado para aplica\xe7\xf5es de chatbots. O armazenamento dos prompts ajudam a contextualizar as conversas com assuntos relevantes e coerentes."}),"\n",(0,s.jsx)(a.p,{children:"Muitos Foundation Models, tem um limite para o context window, que podem receber como entrada dados menores."}),"\n",(0,s.jsx)(a.p,{children:"Ent\xe3o as vezes conversas muito longas podem ser armazenadas e utilizadas em futuras conversas como contexto."}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"alt text",src:o(1893).A+"",width:"766",height:"411"})}),"\n",(0,s.jsx)(a.admonition,{title:"Fonte",type:"tip",children:(0,s.jsx)(a.p,{children:(0,s.jsx)(a.a,{href:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components",children:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components"})})}),"\n",(0,s.jsx)(a.p,{children:"Com isso \xe9 poss\xedvel que as respostas dos prompts possam ser previstas , evitando assim repeti\xe7\xf5es de requests semelhantes para o Foundation Models. Ajudando tamb\xe9m como uma politica de auditoria e compliance onde um time de auditores \xe9 capaz de analisar e regular erros causados por respostas indevidas."}),"\n",(0,s.jsx)(a.h2,{id:"rag",children:"RAG"}),"\n",(0,s.jsx)(a.p,{children:"RAG \xe9 um framework de constru\xe7\xe3o de generative AI que pode ser usado por recusos empresariais ou vector database para superar problemas de limita\xe7\xe3o de conhecimento de um modelo."}),"\n",(0,s.jsx)(a.p,{children:"O Funcionamento do RAG e utiliar o retrivever modelue para encontrar informa\xe7\xf5es relevantes de uma base de daods external, responde o usu\xe1rio atrav\xe9s de prompts."}),"\n",(0,s.jsx)(a.p,{children:"Seguindo o conceito de few-short aqui podemos dizer que ao recuperar os dados de uma base de informa\xe7\xf5es adicionamos ela como contexto no propr\xedo prompt do usu\xe1rio, fazendo com que o modelo entenda e amplie sua base de informa\xe7\xf5es."}),"\n",(0,s.jsx)(a.p,{children:"Exemplo:"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"alt text",src:o(2796).A+"",width:"1371",height:"912"})}),"\n",(0,s.jsx)(a.p,{children:"Perceba que o modelo foi atualizado em janeiro de 2022 por\xe9m conseguiu inferir atrav\xe9s de dados adicionais a informa\xe7\xe3o da data correta, com isso temos talvez aqui um exemplo de RAG na pr\xe1tica."}),"\n",(0,s.jsx)(a.h3,{id:"rag-visualmente",children:"RAG visualmente"}),"\n",(0,s.jsx)(a.p,{children:(0,s.jsx)(a.img,{alt:"alt text",src:o(2855).A+"",width:"1113",height:"682"})}),"\n",(0,s.jsx)(a.p,{children:"Sempre que o usu\xe1rio faz uma intera\xe7\xe3o com o o Foundation Model (modelo ou llm) a um acrescimo de informa\xe7\xe3o adicionada no prompt antes mesmo da requisi\xe7\xe3o chegar no modelo, ou seja, a informa\xe7\xe3o \xe9 pesquisada dentro do vector database e enviada junto com o prompt do usu\xe1rio."}),"\n",(0,s.jsx)(a.h3,{id:"model-fine-tuning",children:"Model Fine-Tuning"}),"\n",(0,s.jsx)(a.p,{children:"Algumas limita\xe7\xf5es do RAG s\xe3o evidentes:"}),"\n",(0,s.jsxs)(a.ul,{children:["\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:"Respostas limitadas ao seu datasets armazenados em sesus data vectors"}),"\n"]}),"\n",(0,s.jsxs)(a.li,{children:["\n",(0,s.jsx)(a.p,{children:"Consulta de informa\xe7\xf5es em runtime, trazendo maior lat\xeancias em alguns cen\xe1rios."}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(a.p,{children:"Por\xe9m quando utilizamos o Fine-Tuning, podemos criar/treinar modelos menores com conhecimentos especifico e espescializado. Hoje temos duas categorias de fine-tuning:"}),"\n",(0,s.jsx)(a.p,{children:"Prompt-based learning e Domain adaptation"}),"\n",(0,s.jsx)(a.h4,{id:"prompt-based-learning",children:"Prompt-based learning"}),"\n",(0,s.jsx)(a.p,{children:"Basicamente aqui voc\xea ensina o modelo a compreender os assuntos com uma rotula\xe7\xe3o especifica, mostrando exemplos atrav\xe9s de pares de respostas e prompts como criar frases e instru\xe7\xf5es."}),"\n",(0,s.jsx)(a.p,{children:"Devido a seu uso ser especializado para uma unica fonte de dados com abordagem especifica, ele n\xe3o \xe9 recomendado a ser usado como um modelo de multi tarefas."}),"\n",(0,s.jsx)(a.h4,{id:"domain-adaptation",children:"Domain adaptation"})]})}function m(e={}){const{wrapper:a}={...(0,n.R)(),...e.components};return a?(0,s.jsx)(a,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},7688:(e,a,o)=>{o.d(a,{A:()=>s});const s=o.p+"assets/images/image-1-67e66710259d7caab3139a5fcf778f8c.png"},2963:(e,a,o)=>{o.d(a,{A:()=>s});const s=o.p+"assets/images/image-2-41c30525266a3432c5af94e978ce2ff6.png"},1893:(e,a,o)=>{o.d(a,{A:()=>s});const s=o.p+"assets/images/image-4-696354123d82cd9aa9cb8ff3748bef86.png"},2796:(e,a,o)=>{o.d(a,{A:()=>s});const s=o.p+"assets/images/image-5-649ffceea005f065d81d9f48a97f6516.png"},2855:(e,a,o)=>{o.d(a,{A:()=>s});const s=o.p+"assets/images/image-6-9da6beaee9340f9a826223abf21dcfb0.png"},1594:(e,a,o)=>{o.d(a,{A:()=>s});const s=o.p+"assets/images/image-11f6b4178f958c629f35382683e2ec2d.png"},8453:(e,a,o)=>{o.d(a,{R:()=>r,x:()=>t});var s=o(6540);const n={},i=s.createContext(n);function r(e){const a=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function t(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),s.createElement(i.Provider,{value:a},e.children)}}}]);