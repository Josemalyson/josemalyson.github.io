"use strict";(self.webpackChunkjosemalyson_github_io=self.webpackChunkjosemalyson_github_io||[]).push([[7206],{70:(e,a,o)=>{o.r(a),o.d(a,{assets:()=>d,contentTitle:()=>r,default:()=>m,frontMatter:()=>i,metadata:()=>t,toc:()=>l});var n=o(4848),s=o(8453);const i={sidebar_position:1},r="Amazon Bedrock",t={id:"aws/bedrock",title:"Amazon Bedrock",description:"O amazon Bedrorck \xe9 um servi\xe7o da AWS para construir e escalar de maneira f\xe1cil aplica\xe7\xf5es de IA Generativa (Generative AI) com modelos fundacionais. Disponibilizando os modelos atrav\xe9s de uma simples chamada via API, gerando aplica\xe7\xe3oes de generative AI com seguran\xe7a, privacidade e responsabilidade AI.",source:"@site/docs/aws/bedrock.md",sourceDirName:"aws",slug:"/aws/bedrock",permalink:"/en/docs/aws/bedrock",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/aws/bedrock.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"AWS",permalink:"/en/docs/category/aws"}},d={},l=[{value:"Modelos suportados",id:"modelos-suportados",level:2},{value:"Explorando o poder da generative AI",id:"explorando-o-poder-da-generative-ai",level:2},{value:"Text summarization",id:"text-summarization",level:3},{value:"Text generation",id:"text-generation",level:3},{value:"Question answering systems",id:"question-answering-systems",level:3},{value:"Agents",id:"agents",level:3},{value:"Foundation Models (Modelos Fundacionais ) e FM Interface",id:"foundation-models-modelos-fundacionais--e-fm-interface",level:2},{value:"Foundation model interface",id:"foundation-model-interface",level:3},{value:"Interface and prompts",id:"interface-and-prompts",level:3},{value:"Inference parameters",id:"inference-parameters",level:3},{value:"Top P or nucleus sampling",id:"top-p-or-nucleus-sampling",level:4},{value:"Top K",id:"top-k",level:4},{value:"Temperature",id:"temperature",level:4}];function c(e){const a={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",ul:"ul",...(0,s.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(a.h1,{id:"amazon-bedrock",children:"Amazon Bedrock"}),"\n",(0,n.jsx)(a.p,{children:"O amazon Bedrorck \xe9 um servi\xe7o da AWS para construir e escalar de maneira f\xe1cil aplica\xe7\xf5es de IA Generativa (Generative AI) com modelos fundacionais. Disponibilizando os modelos atrav\xe9s de uma simples chamada via API, gerando aplica\xe7\xe3oes de generative AI com seguran\xe7a, privacidade e responsabilidade AI."}),"\n",(0,n.jsx)(a.p,{children:"Utilizando o conceito de t\xe9cnicas de customiza\xe7\xe3o de uso dos modelos como fine-tuning e Retrieval Augmented Generation (RAG)."}),"\n",(0,n.jsx)(a.p,{children:"O Amazon Bedrock \xe9 um servi\xe7o serveless onde voc\xea n\xe3o precisa gerenciar sua infra-estrutura."}),"\n",(0,n.jsx)(a.h2,{id:"modelos-suportados",children:"Modelos suportados"}),"\n",(0,n.jsx)(a.p,{children:"Abaixo temos alguns dos modelos suportados, para uso, sendo eles:"}),"\n",(0,n.jsxs)(a.ul,{children:["\n",(0,n.jsx)(a.li,{children:"AI21 Labs"}),"\n",(0,n.jsx)(a.li,{children:"Anthropic"}),"\n",(0,n.jsx)(a.li,{children:"Cohere"}),"\n",(0,n.jsx)(a.li,{children:"Meta"}),"\n",(0,n.jsx)(a.li,{children:"Mistral AI"}),"\n",(0,n.jsx)(a.li,{children:"Stability AI"}),"\n"]}),"\n",(0,n.jsx)(a.h2,{id:"explorando-o-poder-da-generative-ai",children:"Explorando o poder da generative AI"}),"\n",(0,n.jsx)(a.p,{children:"Com o uso do NLP (Natural Language Processing) podemos ter algumas a\xe7\xf5es que podem ser realiadas sendo elas: Text summarization, Text generation, Question answering systems, Agents."}),"\n",(0,n.jsx)(a.h3,{id:"text-summarization",children:"Text summarization"}),"\n",(0,n.jsx)(a.p,{children:"Como o propr\xedo nome nos tr\xe1s refer\xeancia, podemos resumir ou filtrar grandes quantidades de informa\xe7\xf5es utilizando o modelo de LLM ou os FMs (Modelos fundacionais), nos ajudando\nh\xe1 entender informa\xe7\xf5es chaves sobre um determinado assunto de forma limpa e objetiva."}),"\n",(0,n.jsx)(a.h3,{id:"text-generation",children:"Text generation"}),"\n",(0,n.jsx)(a.p,{children:"Nesse cen\xe1rio temos a op\xe7\xe3o de contextualizar os modelos com o objetivo de gerar novos argumentos como resposta, trazendo uma gera\xe7\xe3o mais realista\nda linguagem humana e melhorando a compreens\xe3o de dados, utilizamos as tecnicas que inclue o uso do LangChain e do  Retrieval Augmented Generation (RAG) com a persistecia de embeddings\npara contextualizar nosso modelo."}),"\n",(0,n.jsx)(a.h3,{id:"question-answering-systems",children:"Question answering systems"}),"\n",(0,n.jsx)(a.p,{children:"Basicamente essa op\xe7\xe3o \xe9 a sa\xeddas das informa\xe7\xf5es montadas pelo Text generation dando a possibilidade do usu\xe1rio interagir via modelo de implementa\xe7\xe3o como um chatbot, para entender e buscar informa\xe7\xf5es\ndadas ao seu contexto."}),"\n",(0,n.jsx)(a.h3,{id:"agents",children:"Agents"}),"\n",(0,n.jsx)(a.p,{children:"S\xe3o capazes de entender a linguagem natural requistitadas pelo usu\xe1rio para disponibilizar chamadas via API facilitando a complexidade de tarefas de acesso direto ao modelo. O servi\xe7o de prompt engineering especifico\nde uma company-specific ou domain-specific. No Amazon Bedrock os agentes podem gerenciar infraestrutura, monitoramento, criptografia, permiss\xf5es e invoca\xe7\xf5es senm customiza\xe7\xe3o de c\xf3digo."}),"\n",(0,n.jsx)(a.h1,{id:"componentes-tipicos-de-uma-aplica\xe7\xe3o-com-generative-ai",children:"Componentes tipicos de uma aplica\xe7\xe3o com generative AI"}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.img,{alt:"alt text",src:o(1594).A+"",width:"865",height:"819"})}),"\n",(0,n.jsx)(a.admonition,{title:"Fonte",type:"tip",children:(0,n.jsx)(a.p,{children:(0,n.jsx)(a.a,{href:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components",children:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components"})})}),"\n",(0,n.jsx)(a.h2,{id:"foundation-models-modelos-fundacionais--e-fm-interface",children:"Foundation Models (Modelos Fundacionais ) e FM Interface"}),"\n",(0,n.jsx)(a.h3,{id:"foundation-model-interface",children:"Foundation model interface"}),"\n",(0,n.jsx)(a.p,{children:"As interfaces funcionais de modelo s\xe3o o cora\xe7\xe3o da generative AI, ou seja os pr\xf3prios modelos treinanos com uma enromne escala de dados, s\xe3o disponibilizados para atender a um determinado requisito do usu\xe1rio."}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.img,{alt:"alt text",src:o(7688).A+"",width:"1015",height:"426"})}),"\n",(0,n.jsx)(a.admonition,{title:"Fonte",type:"tip",children:(0,n.jsx)(a.p,{children:(0,n.jsx)(a.a,{href:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components",children:"https://explore.skillbuilder.aws/learn/course/17904/play/94135/module-2-application-components"})})}),"\n",(0,n.jsx)(a.h3,{id:"interface-and-prompts",children:"Interface and prompts"}),"\n",(0,n.jsx)(a.p,{children:"Para que seja poss\xedvel acessar o modelo \xe9 necess\xe1rio que seja fornecido uma interface de (entrada) dados, geralmente temos a disponibiliza\xe7\xe3o de APIs, onde a mesma atrav\xe9s de uma requisi\xe7\xe3o \xe9 capaz de trazer as respostas enviadas via prompt."}),"\n",(0,n.jsx)(a.h3,{id:"inference-parameters",children:"Inference parameters"}),"\n",(0,n.jsx)(a.p,{children:"Durante o uso de prompts, efetivamente os Inference parameters causam uma forte influ\xeancia no output dos Foundation model. As LLMs operam com o uso de token, que podem ser palavaras, letras ou apenas uma parte de uma frase."}),"\n",(0,n.jsx)(a.p,{children:(0,n.jsx)(a.code,{children:"Mil tokens s\xe3o aproximadamente 750 palavras."})}),"\n",(0,n.jsx)(a.h4,{id:"top-p-or-nucleus-sampling",children:"Top P or nucleus sampling"}),"\n",(0,n.jsx)(a.p,{children:"Neste controle de tecnica \xe9 respos\xe1vel por escolher a menor possibilidade de combina\xe7\xe3o de acertividade para o pr\xf3ximo token. Uma alto valor par o Top P como 0.9 pode tornar o resultado o mais deterministico e previsiv\xe9l. Com valores menores pode trazer tokens incoerentes ent\xe3o \xe9 essencial balancear o seu valor."}),"\n",(0,n.jsx)(a.h4,{id:"top-k",children:"Top K"}),"\n",(0,n.jsx)(a.p,{children:"Whereas Top P works based on probabilities, Top K reduces the sample size to the next k probable tokens. Typical k values are from 10 to 100. A k value of 1 is called a greedy strategy because the most probable token is always chosen."}),"\n",(0,n.jsx)(a.h4,{id:"temperature",children:"Temperature"}),"\n",(0,n.jsx)(a.p,{children:"Whereas Top P and Top K control which tokens are chosen based on the model\u2019s output, the temperature parameter affects the model\u2019s output directly. The higher the temperature, the flatter the probability distribution, which means it will be uniform across tokens. The generated tokens will be more creative and random. Lower temperature will polarize the distribution, which make deterministic outputs possible."})]})}function m(e={}){const{wrapper:a}={...(0,s.R)(),...e.components};return a?(0,n.jsx)(a,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},7688:(e,a,o)=>{o.d(a,{A:()=>n});const n=o.p+"assets/images/image-1-67e66710259d7caab3139a5fcf778f8c.png"},1594:(e,a,o)=>{o.d(a,{A:()=>n});const n=o.p+"assets/images/image-11f6b4178f958c629f35382683e2ec2d.png"},8453:(e,a,o)=>{o.d(a,{R:()=>r,x:()=>t});var n=o(6540);const s={},i=n.createContext(s);function r(e){const a=n.useContext(i);return n.useMemo((function(){return"function"==typeof e?e(a):{...a,...e}}),[a,e])}function t(e){let a;return a=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),n.createElement(i.Provider,{value:a},e.children)}}}]);